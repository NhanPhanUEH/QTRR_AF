# app.py ‚Äî K√Ω qu·ªπ & Gi√° ph·∫£i ch·∫°m (60/50/40%) ‚Äî KH√îNG quy·ªÅn ch·ªçn
# Upload: POS.xlsx + MGM.xlsx ‚Üí ƒë·ªçc ƒë√∫ng m√£ SP, th·ªëng k√™, t√≠nh gi√° ph·∫£i ch·∫°m; GI·ªÆ ƒë·∫ßy ƒë·ªß nh√≥m KIM LO·∫†I
# Th√™m: L·ªäCH ƒê√ÅO H·∫†N NH√öNG + so kh·ªõp M√£ Hƒê + c·∫£nh b√°o FND + l∆∞u ICS/CSV nh·∫Øc l·ªãch
# S·ª≠a: b·ªè infer_datetime_format (deprecated), t·∫°o exp_df tr∆∞·ªõc khi d√πng trong TAB "üìÖ ƒê√°o h·∫°n Hƒê m·ªü"

import os, re, unicodedata, uuid
from io import StringIO
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# -------------------- C·∫§U H√åNH TRANG --------------------
st.set_page_config(page_title="K√Ω qu·ªπ & Gi√° ph·∫£i ch·∫°m (60/50/40%) ‚Äî no options", layout="wide")
st.title("K√Ω qu·ªπ & Gi√° TT c·∫ßn ch·∫°m (60/50/40%) ‚Äî Kh√¥ng quy·ªÅn ch·ªçn, ƒê·ª¶ nh√≥m Kim lo·∫°i + Nh·∫Øc FND")

# -------------------- H√ÄM TI·ªÜN √çCH CHUNG --------------------
DEFAULT_PREFIX = "068C"
MARGIN_TARGETS = [60, 50, 40]
MONTH_LETTERS = set("FGHJKMNQUVXZ")  # ch·ªØ th√°ng future

def _fix_cyrillic_like(s: str) -> str:
    """Chu·∫©n h√≥a s√†n: thay k√Ω t·ª± Cyrillic tr√¥ng gi·ªëng Latin."""
    if not isinstance(s, str):
        return s
    s2 = s.strip()
    s2 = (s2
          .replace("–°–í–û–¢", "CBOT")
          .replace("–°–≤–æ—Ç", "CBOT")
          .replace("–°–≤–æ—Ç".upper(), "CBOT"))
    return s2

def _parse_ddmmyyyy(s):
    # pandas m·ªõi kh√¥ng c·∫ßn infer_datetime_format
    return pd.to_datetime(s, errors="coerce", dayfirst=True)

def _strip_accents(s: str) -> str:
    if s is None: return ""
    s = str(s)
    s = unicodedata.normalize("NFKD", s).replace("ƒë","d").replace("ƒê","D")
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = re.sub(r"[^0-9a-zA-Z]+", " ", s)
    return re.sub(r"\s+", " ", s).strip().lower()

def _norm_cols(df: pd.DataFrame):
    return {c: _strip_accents(c) for c in df.columns}

def _find_col(df: pd.DataFrame, candidates, required=False, default=None):
    norm_map = _norm_cols(df)
    inv = {v: k for k, v in norm_map.items()}
    for cand in candidates:
        key = _strip_accents(cand)
        if key in inv:
            return inv[key]
    if required:
        raise ValueError(f"Thi·∫øu c·ªôt b·∫Øt bu·ªôc: {candidates} ‚Äî c·ªôt c√≥: {list(norm_map.values())}")
    return default

def _to_num(x):
    if isinstance(x, (int, float)) or pd.isna(x): return x
    s = str(x).replace(",", "").replace(" ", "").replace("\u00a0","")
    try: return float(s)
    except: return np.nan

def _num_col(df, col, fill=None):
    s = pd.to_numeric(df[col].map(_to_num), errors="coerce") if (col and col in df.columns) else pd.Series(np.nan, index=df.index)
    if fill is not None: s = s.fillna(fill)
    return s

def _safe_num(s):
    return pd.to_numeric(s, errors="coerce").fillna(0.0)

def _looks_like_account(q):
    Q = str(q).strip().upper()
    return bool(re.search(r"[0-9A-Z]", Q)) or Q.endswith("-A")

def _full_acc_from_suffix(suffix):
    s = str(suffix).strip().upper()
    if s.startswith(DEFAULT_PREFIX): return s
    m = re.fullmatch(r"(\d{4,})(-A)?", s)
    return f"{DEFAULT_PREFIX}{m.group(1)}{m.group(2) or ''}" if m else s

def _resolve_account(q, acc_df, col_key):
    Q = str(q).strip().upper()
    hit = acc_df[acc_df[col_key].astype(str).str.upper() == Q]
    if not hit.empty: return hit
    Q2 = _full_acc_from_suffix(Q)
    hit = acc_df[acc_df[col_key].astype(str).str.upper() == Q2]
    if not hit.empty: return hit
    suf = acc_df[acc_df[col_key].astype(str).str.upper().str.endswith(Q)]
    if suf.empty and Q2 != Q:
        suf = acc_df[acc_df[col_key].astype(str).str.upper().str.endswith(Q2)]
    return suf

def extract_raw_token(ma_hd: str) -> str:
    """
    T√°ch token th√¥ t·ª´ 'M√£ Hƒê':
    - N·∫øu chu·ªói k·∫øt th√∫c b·∫±ng 2 s·ªë: c·∫Øt 2 s·ªë nƒÉm, l·∫•y ph·∫ßn tr∆∞·ªõc (PL1NYF26 -> PL1NYF; XWH26 -> XWH)
    - N·∫øu kh√¥ng: l·∫•y block ch·ªØ+s·ªë ƒë·∫ßu ti√™n.
    - Tr·∫£ v·ªÅ ch·ªØ hoa, kh√¥ng kho·∫£ng tr·∫Øng.
    """
    s = (ma_hd or "").strip().upper()
    s = re.sub(r"\s+", "", s)
    m = re.match(r"^([A-Z0-9\.]+?)(\d{2})$", s)
    if m:
        return m.group(1)
    m2 = re.match(r"^([A-Z0-9\.]+)", s)
    return (m2.group(1) if m2 else "").strip()

def to_base_code(raw_token: str) -> str:
    """
    Base code = b·ªè 1 ch·ªØ th√°ng cu·ªëi (F,G,H,J,K,M,N,Q,U,V,X,Z) n·∫øu c√≥.
    V√≠ d·ª•: PL1NYF -> PL1NY; XWH -> XW; SI5COZ -> SI5CO; ZCEZ -> ZCE; SILZ -> SIL
    """
    t = (raw_token or "").strip().upper()
    return t[:-1] if (len(t)>=3 and t[-1] in MONTH_LETTERS) else t

def looks_like_option_str(s: str) -> bool:
    s = (s or "").strip().upper()
    return s.startswith(("C.","P.")) or re.match(r"^(C|P)[\.\-_/ ]", s) is not None

def _read_best_sheet(file, required_keys_like):
    xl = pd.ExcelFile(file)
    best = (None, None, None, -1)
    for s in xl.sheet_names:
        for h in range(0, 6):
            try:
                df = xl.parse(s, header=h)
            except Exception:
                continue
            norm = set(_norm_cols(df).values())
            score = sum(1 for keys in required_keys_like for k in keys if _strip_accents(k) in norm)
            if score > best[3]:
                best = (df, s, h, score)
    if best[0] is None:
        raise ValueError("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c sheet n√†o h·ª£p l·ªá.")
    return best[0], best[1], best[2]

try:
    from pandas.io.formats.style import Styler
except Exception:
    Styler = object  # type: ignore

def style_positions(df: pd.DataFrame) -> Styler:
    cols = df.columns
    def _color_row(r: pd.Series):
        has_pos = ("NetQty" in r.index) and pd.notna(r["NetQty"]) and abs(float(r["NetQty"])) > 0
        css = "background-color: #fff7ed;" if has_pos else ""
        return [css] * len(cols)
    sty = df.style.apply(_color_row, axis=1)
    for t in (60, 50, 40):
        c = f"Delta_to_{t}_%"
        if c in df.columns:
            sty = sty.background_gradient(subset=[c], cmap="RdYlGn_r")
    return sty

# -------------------- L·ªäCH ƒê√ÅO H·∫†N NH√öNG --------------------
SCHED_RAW = r"""STT	T√™n h·ª£p ƒë·ªìng	M√£ h·ª£p ƒë·ªìng	Nh√≥m h√†ng h√≥a	S·ªü giao d·ªãch	Ng√†y th√¥ng b√°o ƒë·∫ßu ti√™n	Ng√†y giao d·ªãch cu·ªëi c√πng
1	D·∫ßu ƒë·∫≠u t∆∞∆°ng 7/25	ZLEN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
2	D·∫ßu ƒë·∫≠u t∆∞∆°ng 8/25	ZLEQ25	N√¥ng s·∫£n	–°–í–û–¢	31/07/2025	14/08/2025
3	D·∫ßu ƒë·∫≠u t∆∞∆°ng 9/25	ZLEU25	N√¥ng s·∫£n	CBOT	29/08/2025	12/09/2025
4	D·∫ßu ƒë·∫≠u t∆∞∆°ng 10/25	ZLEV25	N√¥ng s·∫£n	–°–í–û–¢	30/09/2025	14/10/2025
5	D·∫ßu ƒë·∫≠u t∆∞∆°ng 12/25	ZLEZ25	N√¥ng s·∫£n	–°–í–û–¢	28/11/2025	12/12/2025
6	D·∫ßu ƒë·∫≠u t∆∞∆°ng 1/26	ZLEF26	N√¥ng s·∫£n	–°–í–û–¢	31/12/2025	14/01/2026
7	D·∫ßu ƒë·∫≠u t∆∞∆°ng micro 8/25	MZLQ25	N√¥ng s·∫£n	–°–í–û–¢	25/07/2025	25/07/2025
8	D·∫ßu ƒë·∫≠u t∆∞∆°ng micro 9/25	MZLU25	N√¥ng s·∫£n	–°–í–û–¢	22/08/2025	22/08/2025
9	D·∫ßu ƒë·∫≠u t∆∞∆°ng micro 10/25	MZLV25	N√¥ng s·∫£n	–°–í–û–¢	26/09/2025	26/09/2025
10	D·∫ßu ƒë·∫≠u t∆∞∆°ng micro 12/25	MZLZ25	N√¥ng s·∫£n	–°–í–û–¢	21/11/2025	21/11/2025
11	D·∫ßu ƒë·∫≠u t∆∞∆°ng micro 1/26	MZLF26	N√¥ng s·∫£n	–°–í–û–¢	26/12/2025	26/12/2025
12	ƒê·∫≠u t∆∞∆°ng 7/25	ZSEN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
13	ƒê·∫≠u t∆∞∆°ng 8/25	ZSEQ25	N√¥ng s·∫£n	–°–í–û–¢	31/07/2025	14/08/2025
14	ƒê·∫≠u t∆∞∆°ng 9/25	ZSEU25	N√¥ng s·∫£n	–°–í–û–¢	29/08/2025	12/09/2025
15	ƒê·∫≠u t∆∞∆°ng 11/25	ZSEX25	N√¥ng s·∫£n	–°–í–û–¢	31/10/2025	14/11/2025
16	ƒê·∫≠u t∆∞∆°ng 1/26	ZSEF26	N√¥ng s·∫£n	–°–í–û–¢	31/12/2025	14/01/2026
17	ƒê·∫≠u t∆∞∆°ng mini 7/25	XBN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
18	ƒê·∫≠u t∆∞∆°ng mini 8/25	XBQ25	N√¥ng s·∫£n	–°–í–û–¢	31/07/2025	14/08/2025
19	ƒê·∫≠u t∆∞∆°ng mini 9/25	XBU25	N√¥ng s·∫£n	–°–í–û–¢	29/08/2025	12/09/2025
20	ƒê·∫≠u t∆∞∆°ng mini 11/25	XBX25	N√¥ng s·∫£n	–°–í–û–¢	31/10/2025	14/11/2025
21	ƒê·∫≠u t∆∞∆°ng mini 1/26	XBF26	N√¥ng s·∫£n	–°–í–û–¢	31/12/2025	14/01/2026
22	ƒê·∫≠u t∆∞∆°ng micro 8/25	MZSQ25	N√¥ng s·∫£n	–°–í–û–¢	25/07/2025	25/07/2025
23	ƒê·∫≠u t∆∞∆°ng micro 9/25	MZSU25	N√¥ng s·∫£n	–°–í–û–¢	22/08/2025	22/08/2025
24	ƒê·∫≠u t∆∞∆°ng micro 11/25	MZSX25	N√¥ng s·∫£n	–°–≤–æ—Ç	24/10/2025	24/10/2025
25	ƒê·∫≠u t∆∞∆°ng micro 1/26	MZSF26	N√¥ng s·∫£n	–°–≤–æ—Ç	26/12/2025	26/12/2025
26	Kh√¥ ƒë·∫≠u t∆∞∆°ng 7/25	ZMEN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
27	Kh√¥ ƒë·∫≠u t∆∞∆°ng 8/25	ZMEQ25	N√¥ng s·∫£n	–°–í–û–¢	31/07/2025	14/08/2025
28	Kh√¥ ƒë·∫≠u t∆∞∆°ng 9/25	ZMEU25	N√¥ng s·∫£n	CBOT	29/08/2025	12/09/2025
29	Kh√¥ ƒë·∫≠u t∆∞∆°ng 10/25	ZMEV25	N√¥ng s·∫£n	–°–í–û–¢	30/09/2025	14/10/2025
30	Kh√¥ ƒë·∫≠u t∆∞∆°ng 12/25	ZMEZ25	N√¥ng s·∫£n	–°–≤–æ—Ç	28/11/2025	12/12/2025
31	Kh√¥ ƒë·∫≠u t∆∞∆°ng 1/26	ZMEF26	N√¥ng s·∫£n	–°–í–û–¢	31/12/2025	14/01/2026
32	Kh√¥ ƒë·∫≠u t∆∞∆°ng micro 8/25	MZMQ25	N√¥ng s·∫£n	–°–≤–æ—Ç	25/07/2025	25/07/2025
33	Kh√¥ ƒë·∫≠u t∆∞∆°ng micro 9/25	MZMU25	N√¥ng s·∫£n	–°–í–û–¢	22/08/2025	22/08/2025
34	Kh√¥ ƒë·∫≠u t∆∞∆°ng micro 10/25	MZMV25	N√¥ng s·∫£n	–°–≤–æ—Ç	26/09/2025	26/09/2025
35	Kh√¥ ƒë·∫≠u t∆∞∆°ng micro 12/25	MZMZ25	N√¥ng s·∫£n	–°–í–û–¢	21/11/2025	21/11/2025
36	Kh√¥ ƒë·∫≠u t∆∞∆°ng micro 1/26	MZMF26	N√¥ng s·∫£n	CBOT	26/12/2025	26/12/2025
37	L√∫a m·ª≥ 7/25	ZWAN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
38	L√∫a m·ª≥ 9/25	ZWAU25	N√¥ng s·∫£n	CBOT	29/08/2025	12/09/2025
39	L√∫a m·ª≥ 12/25	ZWAZ25	N√¥ng s·∫£n	–°–í–û–¢	28/11/2025	12/12/2025
40	L√∫a m·ª≥ mini 7/25	XWN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
41	L√∫a m·ª≥ mini 9/25	XWU25	N√¥ng s·∫£n	–°–í–û–¢	29/08/2025	12/09/2025
42	L√∫a m·ª≥ mini 12/25	XWZ25	N√¥ng s·∫£n	CBOT	28/11/2025	12/12/2025
43	L√∫a m·ª≥ micro 9/25	MZWU25	N√¥ng s·∫£n	–°–í–û–¢	22/08/2025	22/08/2025
44	L√∫a m·ª≥ micro 12/25	MZWZ25	N√¥ng s·∫£n	–°–í–û–¢	21/11/2025	21/11/2025
45	L√∫a m·ª≥ Kansas 7/25	KWEN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
46	L√∫a m·ª≥ Kansas 9/25	KWEU25	N√¥ng s·∫£n	–°–≤–æ—Ç	29/08/2025	12/09/2025
47	L√∫a m·ª≥ Kansas 12/25	KWEZ25	N√¥ng s·∫£n	–°–í–û–¢	28/11/2025	12/12/2025
48	Ng√¥ 7/25	ZCEN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
49	Ng√¥ 9/25	ZCEU25	N√¥ng s·∫£n	CBOT	29/08/2025	12/09/2025
50	Ng√¥ 12/25	ZCEZ25	N√¥ng s·∫£n	–°–í–û–¢	28/11/2025	12/12/2025
51	Ng√¥ mini 7/25	XCN25	N√¥ng s·∫£n	–°–í–û–¢	30/06/2025	14/07/2025
52	Ng√¥ mini 9/25	XCU25	N√¥ng s·∫£n	–°–í–û–¢	29/08/2025	12/09/2025
53	Ng√¥ mini 12/25	XCZ25	N√¥ng s·∫£n	–°–≤–æ—Ç	28/11/2025	12/12/2025
54	Ng√¥ micro 9/25	MZCU25	N√¥ng s·∫£n	–°–í–û–¢	22/08/2025	22/08/2025
55	Ng√¥ micro 12/25	MZCZ25	N√¥ng s·∫£n	–°–í–û–¢	21/11/2025	21/11/2025
56	D·∫ßu c·ªç th√¥ 7/25	MPON25	Nguy√™n li·ªáu	BMDX	30/06/2025	15/07/2025
57	D·∫ßu c·ªç th√¥ 8/25	MPOQ25	Nguy√™n li·ªáu	BMDX	31/07/2025	15/08/2025
58	D·∫ßu c·ªç th√¥ 9/25	MPOU25	Nguy√™n li·ªáu	BMDX	29/08/2025	15/09/2025
59	D·∫ßu c·ªç th√¥ 10/25	MPOV25	Nguy√™n li·ªáu	BMDX	30/09/2025	15/10/2025
60	D·∫ßu c·ªç th√¥ 11/25	MPOX25	Nguy√™n li·ªáu	BMDX	31/10/2025	14/11/2025
61	D·∫ßu c·ªç th√¥ 12/25	MPOZ25	Nguy√™n li·ªáu	BMDX	28/11/2025	15/12/2025
62	D·∫ßu c·ªç th√¥ 1/26	MPOF26	Nguy√™n li·ªáu	BMDX	31/12/2025	15/01/2026
63	C√† ph√™ Robusta 7/25	LRCN25	Nguy√™n li·ªáu	ICE EU	25/06/2025	25/07/2025
64	C√† ph√™ Robusta 9/25	LRCU25	Nguy√™n li·ªáu	ICE EU	26/08/2025	24/09/2025
65	C√† ph√™ Robusta 11/25	LRCX25	Nguy√™n li·ªáu	ICE EU	28/10/2025	24/11/2025
66	C√† ph√™ Robusta 1/26	LRCF26	Nguy√™n li·ªáu	ICE EU	24/12/2025	26/01/2026
67	ƒê∆∞·ªùng tr·∫Øng 8/25	QWQ25	Nguy√™n li·ªáu	ICE EU	16/07/2025	16/07/2025
68	ƒê∆∞·ªùng tr·∫Øng 10/25	QWV25	Nguy√™n li·ªáu	ICE EU	15/09/2025	15/09/2025
69	ƒê∆∞·ªùng tr·∫Øng 12/25	QWZ25	Nguy√™n li·ªáu	ICE EU	14/11/2025	14/11/2025
70	B√¥ng s·ª£i 7/25	CTEN25	Nguy√™n li·ªáu	ICE US	24/06/2025	09/07/2025
71	B√¥ng s·ª£i 10/25	CTEV25	Nguy√™n li·ªáu	ICE US	24/09/2025	09/10/2025
72	B√¥ng s·ª£i 12/25	CTEZ25	Nguy√™n li·ªáu	ICE US	21/11/2025	08/12/2025
73	Ca cao 7/25	CCEN25	Nguy√™n li·ªáu	ICE US	24/06/2025	16/07/2025
74	Ca cao 9/25	CCEU25	Nguy√™n li·ªáu	ICE US	25/08/2025	15/09/2025
75	Ca cao 12/25	CCEZ25	Nguy√™n li·ªáu	ICE US	21/11/2025	15/12/2025
76	C√† ph√™ Arabica 7/25	KCEN25	Nguy√™n li·ªáu	ICE US	20/06/2025	21/07/2025
77	C√† ph√™ Arabica 9/25	KCEU25	Nguy√™n li·ªáu	ICE US	21/08/2025	18/09/2025
78	C√† ph√™ Arabica 12/25	KCEZ25	Nguy√™n li·ªáu	ICE US	19/11/2025	18/12/2025
79	ƒê∆∞·ªùng 10/25	SBEV25	Nguy√™n li·ªáu	ICE US	30/09/2025	30/09/2025
80	Cao su RSS3 7/25	TRUN25	Nguy√™n li·ªáu	OSE	25/07/2025	25/07/2025
81	Cao su RSS3 8/25	TRUQ25	Nguy√™n li·ªáu	OSE	25/08/2025	25/08/2025
82	Cao su RSS3 9/25	TRUU25	Nguy√™n li·ªáu	OSE	24/09/2025	24/09/2025
83	Cao su RSS3 10/25	TRUV25	Nguy√™n li·ªáu	OSE	27/10/2025	27/10/2025
84	Cao su RSS3 11/25	TRUX25	Nguy√™n li·ªáu	OSE	21/11/2025	21/11/2025
85	Cao su RSS3 12/25	TRUZ25	Nguy√™n li·ªáu	OSE	22/12/2025	22/12/2025
86	Cao su TSR20 8/25	ZFTQ25	Nguy√™n li·ªáu	SGX	31/07/2025	31/07/2025
87	Cao su TSR20 9/25	ZFTU25	Nguy√™n li·ªáu	SGX	29/08/2025	29/08/2025
88	Cao su TSR20 10/25	ZFTV25	Nguy√™n li·ªáu	SGX	30/09/2025	30/09/2025
89	Cao su TSR20 11/25	ZFTX25	Nguy√™n li·ªáu	SGX	31/10/2025	31/10/2025
90	Cao su TSR20 12/25	ZFTZ25	Nguy√™n li·ªáu	SGX	28/11/2025	28/11/2025
91	Cao su TSR20 1/26	ZFTF26	Nguy√™n li·ªáu	SGX	30/12/2025	30/12/2025
92	B·∫°c Nano ACM 9/2025	SI5COU25	Kim lo·∫°i	ACM	27/08/2025	27/08/2025
93	B·∫°c Nano ACM 12/2025	SI5COZ25	Kim lo·∫°i	ACM	25/11/2025	25/11/2025
94	B·∫°c Nano ACM 1/2026	SI5COF26	Kim lo·∫°i	ACM	29/12/2025	29/12/2025
95	B·∫°ch kim Nano ACM 10/2025	PL1NYV25	Kim lo·∫°i	ACM	26/09/2025	26/09/2025
96	B·∫°ch kim Nano ACM 1/2026	PL1NYF26	Kim lo·∫°i	ACM	29/12/2025	29/12/2025
97	ƒê·ªìng Nano ACM 8/2025	CP2COQ25	Kim lo·∫°i	ACM	29/07/2025	29/07/2025
98	ƒê·ªìng Nano ACM 9/2025	CP2COU25	Kim lo·∫°i	ACM	27/08/2025	27/08/2025
99	ƒê·ªìng Nano ACM 10/2025	CP2COV25	Kim lo·∫°i	ACM	26/09/2025	26/09/2025
100	ƒê·ªìng Nano ACM 11/2025	CP2COX25	Kim lo·∫°i	ACM	29/10/2025	29/10/2025
101	ƒê·ªìng Nano ACM 12/2025	CP2COZ25	Kim lo·∫°i	ACM	25/11/2025	25/11/2025
102	ƒê·ªìng Nano ACM 1/2026	CP2COF26	Kim lo·∫°i	ACM	29/12/2025	29/12/2025
103	B·∫°c 7/25	SIEN25	Kim lo·∫°i	COMEX	30/06/2025	29/07/2025
104	B·∫°c 8/25	SIEQ25	Kim lo·∫°i	COMEX	31/07/2025	27/08/2025
105	B·∫°c 9/25	SIEU25	Kim lo·∫°i	COMEX	29/08/2025	26/09/2025
106	B·∫°c 10/25	SIEV25	Kim lo·∫°i	COMEX	30/09/2025	29/10/2025
107	B·∫°c 11/25	SIEX25	Kim lo·∫°i	COMEX	31/10/2025	25/11/2025
108	B·∫°c 12/25	SIEZ25	Kim lo·∫°i	COMEX	28/11/2025	29/12/2025
109	B·∫°c 1/26	SIEF26	Kim lo·∫°i	COMEX	31/12/2025	28/01/2026
110	B·∫°c mini 9/25	MQIU25	Kim lo·∫°i	COMEX	27/08/2025	27/08/2025
111	B·∫°c mini 12/25	MQIZ25	Kim lo·∫°i	COMEX	25/11/2025	25/11/2025
112	B·∫°c mini 1/26	MQIF26	Kim lo·∫°i	COMEX	29/12/2025	29/12/2025
113	B·∫°c micro 7/25	SILN25	Kim lo·∫°i	COMEX	30/06/2025	29/07/2025
114	B·∫°c micro 8/25	SILQ25	Kim lo·∫°i	COMEX	31/07/2025	27/08/2025
115	B·∫°c micro 9/25	SILU25	Kim lo·∫°i	COMEX	29/08/2025	26/09/2025
116	B·∫°c micro 10/25	SILV25	Kim lo·∫°i	COMEX	30/09/2025	29/10/2025
117	B·∫°c micro 11/25	SILX25	Kim lo·∫°i	COMEX	31/10/2025	25/11/2025
118	B·∫°c micro 12/25	SILZ25	Kim lo·∫°i	COMEX	28/11/2025	29/12/2025
119	B·∫°c micro 1/26	SILF26	Kim lo·∫°i	COMEX	31/12/2025	28/01/2026
120	ƒê·ªìng 7/25	CPEN25	Kim lo·∫°i	COMEX	30/06/2025	29/07/2025
121	ƒê·ªìng 8/25	CPEQ25	Kim lo·∫°i	COMEX	31/07/2025	27/08/2025
122	ƒê·ªìng 9/25	CPEU25	Kim lo·∫°i	COMEX	29/08/2025	26/09/2025
123	ƒê·ªìng 10/25	CPEV25	Kim lo·∫°i	COMEX	30/09/2025	29/10/2025
124	ƒê·ªìng 11/25	CPEX25	Kim lo·∫°i	COMEX	31/10/2025	25/11/2025
125	ƒê·ªìng 12/25	CPEZ25	Kim lo·∫°i	COMEX	28/11/2025	29/12/2025
126	ƒê·ªìng 1/26	CPEF26	Kim lo·∫°i	COMEX	31/12/2025	28/01/2026
127	ƒê·ªìng mini 8/25	MQCQ25	Kim lo·∫°i	COMEX	29/07/2025	29/07/2025
128	ƒê·ªìng mini 9/25	MQCU25	Kim lo·∫°i	COMEX	27/08/2025	27/08/2025
129	ƒê·ªìng mini 10/25	MQCV25	Kim lo·∫°i	COMEX	26/09/2025	26/09/2025
130	ƒê·ªìng mini 11/25	MQCX25	Kim lo·∫°i	COMEX	29/10/2025	29/10/2025
131	ƒê·ªìng mini 12/25	MQCZ25	Kim lo·∫°i	COMEX	25/11/2025	25/11/2025
132	ƒê·ªìng mini 1/26	MQCF26	Kim lo·∫°i	COMEX	29/12/2025	29/12/2025
133	ƒê·ªìng micro 8/25	MHGQ25	Kim lo·∫°i	COMEX	29/07/2025	29/07/2025
134	ƒê·ªìng micro 9/25	MHGU25	Kim lo·∫°i	COMEX	27/08/2025	27/08/2025
135	ƒê·ªìng micro 10/25	MHGV25	Kim lo·∫°i	COMEX	26/09/2025	26/09/2025
136	ƒê·ªìng micro 11/25	MHGX25	Kim lo·∫°i	COMEX	29/10/2025	29/10/2025
137	ƒê·ªìng micro 12/25	MHGZ25	Kim lo·∫°i	COMEX	25/11/2025	25/11/2025
138	ƒê·ªìng micro 1/26	MHGF26	Kim lo·∫°i	COMEX	29/12/2025	29/12/2025
139	Nh√¥m COMEX 7/25	ALIN25	Kim lo·∫°i	COMEX	30/06/2025	29/07/2025
140	Nh√¥m COMEX 8/25	ALIQ25	Kim lo·∫°i	COMEX	31/07/2025	27/08/2025
141	Nh√¥m COMEX 9/25	ALIU25	Kim lo·∫°i	COMEX	29/08/2025	26/09/2025
142	Nh√¥m COMEX 10/25	ALIV25	Kim lo·∫°i	COMEX	30/09/2025	29/10/2025
143	Nh√¥m COMEX 11/25	ALIX25	Kim lo·∫°i	COMEX	31/10/2025	25/11/2025
144	Nh√¥m COMEX 12/25	ALIZ25	Kim lo·∫°i	COMEX	28/11/2025	29/12/2025
145	Nh√¥m COMEX 1/26	ALIF26	Kim lo·∫°i	COMEX	31/12/2025	28/01/2026
146	B·∫°ch kim 7/25	PLEN25	Kim lo·∫°i	NYMEX	30/06/2025	29/07/2025
147	B·∫°ch kim 8/25	PLEQ25	Kim lo·∫°i	NYMEX	31/07/2025	27/08/2025
148	B·∫°ch kim 9/25	PLEU25	Kim lo·∫°i	NYMEX	29/08/2025	26/09/2025
149	B·∫°ch kim 10/25	PLEV25	Kim lo·∫°i	NYMEX	30/09/2025	29/10/2025
150	B·∫°ch kim 11/25	PLEX25	Kim lo·∫°i	NYMEX	31/10/2025	25/11/2025
151	B·∫°ch kim 12/25	PLEZ25	Kim lo·∫°i	NYMEX	28/11/2025	29/12/2025
152	B·∫°ch kim 1/26	PLEF26	Kim lo·∫°i	NYMEX	31/12/2025	28/01/2026
153	Qu·∫∑ng s·∫Øt 7/25	FEFN25	Kim lo·∫°i	SGX	31/07/2025	31/07/2025
154	Qu·∫∑ng s·∫Øt 8/25	FEFQ25	Kim lo·∫°i	SGX	29/08/2025	29/08/2025
155	Qu·∫∑ng s·∫Øt 9/25	FEFU25	Kim lo·∫°i	SGX	30/09/2025	30/09/2025
156	Qu·∫∑ng s·∫Øt 10/25	FEFV25	Kim lo·∫°i	SGX	31/10/2025	31/10/2025
157	Qu·∫∑ng s·∫Øt 11/25	FEFX25	Kim lo·∫°i	SGX	28/11/2025	28/11/2025
158	Qu·∫∑ng s·∫Øt 12/25	FEFZ25	Kim lo·∫°i	SGX	31/12/2025	31/12/2025
159	ƒê·ªìng LME	LDKZ/CAD	Kim lo·∫°i	LME	02 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ƒë√°o h·∫°n c·ªßa h·ª£p ƒë·ªìng	
160	Nh√¥m LME	LALZ/AHD	Kim lo·∫°i	LME	02 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ƒë√°o h·∫°n c·ªßa h·ª£p ƒë·ªìng	
161	Ch√¨ LME	LEDZ/PBD	Kim lo·∫°i	LME	02 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ƒë√°o h·∫°n c·ªßa h·ª£p ƒë·ªìng	
162	Thi·∫øc LME	LTIZ/SND	Kim lo·∫°i	LME	02 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ƒë√°o h·∫°n c·ªßa h·ª£p ƒë·ªìng	
163	K·∫Ωm LME	LZHZ/ZDS	Kim lo·∫°i	LME	02 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ƒë√°o h·∫°n c·ªßa h·ª£p ƒë·ªìng	
164	Niken LME	LNIZ/NID	Kim lo·∫°i	LME	02 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ƒë√°o h·∫°n c·ªßa h·ª£p ƒë·ªìng	
165	Th√©p thanh v·∫±n FOB Th·ªï Nhƒ© K·ª≥ 7/25	SSRN25	Kim lo·∫°i	LME	31/07/2025	31/07/2025
166	Th√©p thanh v·∫±n FOB Th·ªï Nhƒ© K·ª≥ 8/25	SSRQ25	Kim lo·∫°i	LME	29/08/2025	29/08/2025
167	Th√©p thanh v·∫±n FOB Th·ªï Nhƒ© K·ª≥ 9/25	SSRU25	Kim lo·∫°i	LME	30/09/2025	30/09/2025
168	Th√©p thanh v·∫±n FOB Th·ªï Nhƒ© K·ª≥ 10/25	SSRV25	Kim lo·∫°i	LME	31/10/2025	31/10/2025
169	Th√©p thanh v·∫±n FOB Th·ªï Nhƒ© K·ª≥ 11/25	SSRX25	Kim lo·∫°i	LME	28/11/2025	28/11/2025
170	Th√©p thanh v·∫±n FOB Th·ªï Nhƒ© K·ª≥ 12/25	SSRZ25	Kim lo·∫°i	LME	31/12/2025	31/12/2025
171	Th√©p ph·∫ø li·ªáu CFR Th·ªï Nhƒ© K·ª≥ 7/25	SSCN25	Kim lo·∫°i	LME	31/07/2025	31/07/2025
172	Th√©p ph·∫ø li·ªáu CFR Th·ªï Nhƒ© K·ª≥ 8/25	SSCQ25	Kim lo·∫°i	LME	29/08/2025	29/08/2025
173	Th√©p ph·∫ø li·ªáu CFR Th·ªï Nhƒ© K·ª≥ 9/25	SSCU25	Kim lo·∫°i	LME	30/09/2025	30/09/2025
174	Th√©p ph·∫ø li·ªáu CFR Th·ªï Nhƒ© K·ª≥ 10/25	SSCV25	Kim lo·∫°i	LME	31/10/2025	31/10/2025
175	Th√©p ph·∫ø li·ªáu CFR Th·ªï Nhƒ© K·ª≥ 11/25	SSCX25	Kim lo·∫°i	LME	28/11/2025	28/11/2025
176	Th√©p ph·∫ø li·ªáu CFR Th·ªï Nhƒ© K·ª≥ 12/25	SSCZ25	Kim lo·∫°i	LME	31/12/2025	31/12/2025
177	Th√©p cu·ªôn c√°n n√≥ng FOB Trung Qu·ªëc 7/25	LHCN25	Kim lo·∫°i	LME	31/07/2025	31/07/2025
178	Th√©p cu·ªôn c√°n n√≥ng FOB Trung Qu·ªëc 8/25	LHCQ25	Kim lo·∫°i	LME	29/08/2025	29/08/2025
179	Th√©p cu·ªôn c√°n n√≥ng FOB Trung Qu·ªëc 9/25	LHCU25	Kim lo·∫°i	LME	30/09/2025	30/09/2025
180	Th√©p cu·ªôn c√°n n√≥ng FOB Trung Qu·ªëc 10/25	LHCV25	Kim lo·∫°i	LME	31/10/2025	31/10/2025
181	Th√©p cu·ªôn c√°n n√≥ng FOB Trung Qu·ªëc 11/25	LHCX25	Kim lo·∫°i	LME	28/11/2025	28/11/2025
182	Th√©p cu·ªôn c√°n n√≥ng FOB Trung Qu·ªëc 12/25	LHCZ25	Kim lo·∫°i	LME	31/12/2025	31/12/2025
"""

def build_embedded_schedule() -> pd.DataFrame:
    df = pd.read_csv(StringIO(SCHED_RAW), sep="\t", dtype=str, keep_default_na=False)
    df = df.rename(columns={
        "STT":"STT",
        "T√™n h·ª£p ƒë·ªìng":"T√™n Hƒê (lich)",
        "M√£ h·ª£p ƒë·ªìng":"M√£ Hƒê",
        "Nh√≥m h√†ng h√≥a":"Nh√≥m (lich)",
        "S·ªü giao d·ªãch":"S·ªü GD",
        "Ng√†y th√¥ng b√°o ƒë·∫ßu ti√™n":"FND",
        "Ng√†y giao d·ªãch cu·ªëi c√πng":"LTD",
    })
    df["M√£ Hƒê"] = df["M√£ Hƒê"].str.strip().str.upper()
    df["S·ªü GD"] = df["S·ªü GD"].map(_fix_cyrillic_like)
    df["FND"] = _parse_ddmmyyyy(df["FND"])
    df["LTD"] = _parse_ddmmyyyy(df["LTD"])
    df = df.sort_values(["M√£ Hƒê"]).reset_index(drop=True)

    out_dir = os.path.join(os.path.dirname(__file__) if '__file__' in globals() else ".", "data")
    os.makedirs(out_dir, exist_ok=True)
    xlsx_path = os.path.join(out_dir, "expiry_schedule_mxv_2025-09-23.xlsx")
    csv_path  = os.path.join(out_dir, "expiry_schedule_mxv_2025-09-23.csv")
    try:
        df.to_excel(xlsx_path, index=False)
    except Exception:
        pass
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    return df

SCHEDULE_EMBEDDED = build_embedded_schedule()

# -------------------- SIDEBAR --------------------
st.sidebar.header("T·∫£i d·ªØ li·ªáu")
pos_file = st.sidebar.file_uploader("1) Tr·∫°ng th√°i m·ªü (Excel)", type=["xlsx","xls"])
mgm_file = st.sidebar.file_uploader("2) Danh s√°ch qu·∫£n l√Ω k√Ω qu·ªπ (Excel)", type=["xlsx","xls"])
fx_vnd_usd = st.sidebar.number_input("T·ª∑ gi√° quy ƒë·ªïi VND ‚Üí USD", min_value=10000, max_value=40000, value=25000, step=50)
alert_days = st.sidebar.number_input("C·∫£nh b√°o FND tr∆∞·ªõc (ng√†y)", min_value=1, max_value=60, value=14, step=1)
show_debug = st.sidebar.checkbox("Hi·ªÉn th·ªã debug c·ªôt", value=False)

if not pos_file or not mgm_file:
    st.info("H√£y t·∫£i **c·∫£ hai** file Excel: POS + MGM.")
    st.stop()

# -------------------- ƒê·ªåC FILE POS / MGM --------------------
pos_require = [
    ["m√£ hƒë","ma hd","m√£ h·ª£p ƒë·ªìng","ma hop dong"],
    ["m√£ tkgd","ma tkgd","tkgd"],
    ["gi√° tt","gia tt","gia thi truong","gia thuc te"],
]
mgm_require = [
    ["m√£ tkgd","ma tkgd","tkgd"],
    ["gia tri rong ky quy usd","gi√° tr·ªã r√≤ng k√Ω qu·ªπ usd","gi√° tr·ªã r√≤ng k√Ω qu·ªπ (usd)","equity usd","equity_now"],
    ["ty le ky quy hien tai","t·ª∑ l·ªá k√Ω qu·ªπ hi·ªán t·∫°i","margin_now","margin ratio","ty le ky quy hien tai (%)","t·ª∑ l·ªá k√Ω qu·ªπ hi·ªán t·∫°i (%)"],
]

pos_raw, pos_sheet, pos_header = _read_best_sheet(pos_file, pos_require)
mgm_raw, mgm_sheet, mgm_header = _read_best_sheet(mgm_file, mgm_require)

if show_debug:
    st.caption(f"POS: sheet **{pos_sheet}** header @{pos_header} | MGM: sheet **{mgm_sheet}** header @{mgm_header}")
    st.write("POS cols:", list(_norm_cols(pos_raw).values()))
    st.write("MGM cols:", list(_norm_cols(mgm_raw).values()))

# -------------------- CHU·∫®N H√ìA POS --------------------
c_mahd  = _find_col(pos_raw, ["m√£ hƒë","ma hd","m√£ h·ª£p ƒë·ªìng","ma hop dong"], required=True)
c_tkgd  = _find_col(pos_raw, ["m√£ tkgd","ma tkgd","tkgd"], required=True)
c_ten   = _find_col(pos_raw, ["t√™n tkgd","ten tkgd","khach hang"], required=False)
c_tenhd = _find_col(pos_raw, ["t√™n hƒë","ten hd","t√™n h·ª£p ƒë·ªìng"], required=False)
c_sp    = _find_col(pos_raw, ["sp_magd","m√£ giao d·ªãch","ma gd","ma hang","ma sp"], required=False)
c_buy   = _find_col(pos_raw, ["kl mua","so luong mua"], required=False)
c_sell  = _find_col(pos_raw, ["kl b√°n","kl ban","so luong ban"], required=False)
c_net   = _find_col(pos_raw, ["netqty","net qty","kl rong"], required=False)
c_giatt = _find_col(pos_raw, ["gi√° tt","gia tt","gia thi truong","gia thuc te"], required=True)
c_giatb = _find_col(pos_raw, ["gi√° tb","gia tb","gia vao lenh"], required=False)
c_tick  = _find_col(pos_raw, ["ticksize","tick size","buoc gia"], required=False)
c_imrow = _find_col(pos_raw, ["im_row","im_row_expect","im position","im per row","im/vithe"], required=False)
c_mult  = _find_col(pos_raw, ["contract_multiplier","multiplier","he so lot","lotsize"], required=False)

pos = pos_raw.copy()
pos["M√£ Hƒê"]    = pos[c_mahd].astype(str).str.strip().str.upper()
pos["TKGD_KEY"] = pos[c_tkgd].astype(str)
pos["T√™n TKGD"] = pos[c_ten].astype(str) if c_ten else ""
pos["T√™n Hƒê"]   = pos[c_tenhd].astype(str) if c_tenhd else ""
pos["SP_MaGD"]  = pos[c_sp].astype(str) if c_sp else ""

# lo·∫°i quy·ªÅn ch·ªçn theo SP_MaGD n·∫øu c√≥
is_opt = pos["SP_MaGD"].map(looks_like_option_str)
if is_opt.any():
    st.warning(f"ƒê√£ lo·∫°i **{int(is_opt.sum())}** d√≤ng quy·ªÅn ch·ªçn theo SP_MaGD (prefix C./P.).")
pos = pos.loc[~is_opt].copy()

pos["Gi√° TT"] = _num_col(pos, c_giatt)
pos["Gi√° TB"] = _num_col(pos, c_giatb)
pos["KL Mua"] = _num_col(pos, c_buy, 0.0) if c_buy else pd.Series(0.0, index=pos.index)
pos["KL B√°n"] = _num_col(pos, c_sell, 0.0) if c_sell else pd.Series(0.0, index=pos.index)
if c_net:
    pos["NetQty"] = _num_col(pos, c_net).fillna(pos["KL Mua"] - pos["KL B√°n"])
else:
    pos["NetQty"] = (pos["KL Mua"] - pos["KL B√°n"]).fillna(0.0)

pos["TickSize_POS"] = _num_col(pos, c_tick)
pos["IM_row_file"]  = _num_col(pos, c_imrow)
pos["Mult_POS"]     = _num_col(pos, c_mult)

# -------------------- B√ìC M√É / ALIAS --------------------
pos["SP_RawToken"] = pos["M√£ Hƒê"].map(extract_raw_token)
pos["SP_Base"]     = pos["SP_RawToken"].map(to_base_code)

ALIAS = {
    "ZCEZ":"ZCE", "ZCEH":"ZCE", "ZCEK":"ZCE", "ZCEN":"ZCE", "ZCEU":"ZCE", "ZCEV":"ZCE", "ZCEX":"ZCE",
    "ZWAZ":"ZWA", "ZWAH":"ZWA", "ZWAK":"ZWA", "ZWAN":"ZWA", "ZWAU":"ZWA", "ZWAV":"ZWA", "ZWAX":"ZWA",
    "XWH":"XW", "XWZ":"XW", "XWK":"XW", "XWU":"XW",
    "XCZ":"XC", "XCH":"XC", "XCK":"XC", "XCU":"XC",
    "PLEF":"PLE", "PLEJ":"PLE", "PLEK":"PLE", "PLEM":"PLE", "PLEN":"PLE",
    "SILZ":"SIL", "SILH":"SIL", "SILK":"SIL",
    "PL1NYF":"PL1NY",
    "SI5COZ":"SI5CO",
    "CP2COZ":"CP2CO",
    "SBEH":"SBE", "SBEK":"SBE", "SBEV":"SBE", "SBEZ":"SBE",
}
pos["SP_Base_norm"] = pos["SP_Base"].replace(ALIAS)

# -------------------- CATALOG T√çCH H·ª¢P --------------------
cat = pd.DataFrame([
    # N√¥ng nghi·ªáp
    ("ZSE","ƒê·∫≠u t∆∞∆°ng CBOT","n√¥ng nghi·ªáp",5000,"cent/gi·∫°",0.25,0.01,58_256_000),
    ("XB","ƒê·∫≠u t∆∞∆°ng mini CBOT","n√¥ng nghi·ªáp",1000,"cent/gi·∫°",0.125,0.01,11_651_200),
    ("MZS","ƒê·∫≠u t∆∞∆°ng micro CBOT","n√¥ng nghi·ªáp",500,"cent/gi·∫°",0.5,0.01,6_911_280),
    ("ZLE","D·∫ßu ƒë·∫≠u t∆∞∆°ng CBOT","n√¥ng nghi·ªáp",60000,"cent/pound",0.01,0.01,61_168_800),
    ("ZME","Kh√¥ ƒë·∫≠u t∆∞∆°ng CBOT","n√¥ng nghi·ªáp",100,"USD/t·∫•n thi·∫øu",0.1,1.0,45_148_400),
    ("MZM","Kh√¥ ƒë·∫≠u t∆∞∆°ng micro","n√¥ng nghi·ªáp",10,"USD/t·∫•n thi·∫øu",0.2,1.0,4_528_080),
    ("ZCE","Ng√¥ CBOT","n√¥ng nghi·ªáp",5000,"cent/gi·∫°",0.25,0.01,28_413_040),
    ("XC","Ng√¥ mini CBOT","n√¥ng nghi·ªáp",1000,"cent/gi·∫°",0.125,0.01,5_693_200),
    ("ZWA","L√∫a m√¨ CBOT","n√¥ng nghi·ªáp",5000,"cent/gi·∫°",0.25,0.01,48_061_200),
    ("XW","L√∫a m√¨ mini CBOT","n√¥ng nghi·ªáp",1000,"cent/gi·∫°",0.125,0.01,9_612_240),
    ("MZW","L√∫a m√¨ micro CBOT","n√¥ng nghi·ªáp",500,"cent/gi·∫°",0.5,0.01,4_819_360),
    ("KWE","L√∫a m√¨ Kansas CBOT","n√¥ng nghi·ªáp",5000,"cent/gi·∫°",0.25,0.01,46_604_800),
    # Kim lo·∫°i
    ("PLE","B·∫°ch kim NYMEX","kim lo·∫°i",50,"USD/troy oz",0.1,1.0,145_640_000),
    ("PL1NY","B·∫°ch kim Nano ACM","kim lo·∫°i",5,"USD/troy oz",0.1,1.0,8_976_720),
    ("SIE","B·∫°c COMEX","kim lo·∫°i",5000,"USD/troy oz",0.005,1.0,436_920_000),
    ("MQI","B·∫°c mini COMEX","kim lo·∫°i",2500,"USD/troy oz",0.0125,1.0,218_460_000),
    ("SIL","B·∫°c micro COMEX","kim lo·∫°i",1000,"USD/troy oz",0.005,1.0,87_384_000),
    ("SI5CO","B·∫°c Nano ACM","kim lo·∫°i",100,"USD/troy oz",0.005,1.0,5_057_680),
    ("CPE","ƒê·ªìng COMEX","kim lo·∫°i",25000,"USD/pound",0.0005,1.0,262_152_000),
    ("MQC","ƒê·ªìng mini COMEX","kim lo·∫°i",12500,"USD/pound",0.002,1.0,131_076_000),
    ("MHG","ƒê·ªìng micro COMEX","kim lo·∫°i",2500,"USD/pound",0.0005,1.0,26_215_200),
    ("CP2CO","ƒê·ªìng Nano ACM","kim lo·∫°i",1000,"USD/pound",0.0005,1.0,5_296_000),
    ("ALI","Nh√¥m COMEX","kim lo·∫°i",25,"USD/ton",0.25,1.0,101_948_000),
    # Nguy√™n li·ªáu CN
    ("SBE","ƒê∆∞·ªùng 11 ICE US","nguy√™n li·ªáu c√¥ng nghi·ªáp",112000,"cent/pound",0.01,0.01,28_386_560),
    ("QW","ƒê∆∞·ªùng tr·∫Øng ICE EU","nguy√™n li·ªáu c√¥ng nghi·ªáp",50,"USD/t·∫•n",0.1,1.0,46_287_040),
    ("KCE","C√† ph√™ Arabica ICE US","nguy√™n li·ªáu c√¥ng nghi·ªáp",37500,"cent/pound",0.05,0.01,337_858_320),
    ("LRC","C√† ph√™ Robusta ICE EU","nguy√™n li·ªáu c√¥ng nghi·ªáp",10,"USD/t·∫•n",1.0,1.0,164_864_480),
    ("CTE","B√¥ng ICE US","nguy√™n li·ªáu c√¥ng nghi·ªáp",50000,"cent/pound",0.01,0.01,43_294_800),
    ("CCE","Cacao ICE US","nguy√™n li·ªáu c√¥ng nghi·ªáp",10,"USD/t·∫•n",1.0,1.0,255_161_280),
    ("TRU","Cao su RSS3","nguy√™n li·ªáu c√¥ng nghi·ªáp",5000,"JPY/kh·ªëi",0.1,np.nan,525_141_000),
    ("ZFT","Cao su TSR20","nguy√™n li·ªáu c√¥ng nghi·ªáp",10,"USD/kh·ªëi",1.0,1.0,17_476_800),
    ("MPO","D·∫ßu c·ªç th√¥","nguy√™n li·ªáu c√¥ng nghi·ªáp",25,"USD/t·∫•n",1.0,1.0,1_288_000),
], columns=["SP_Base","SP_Ten","SP_Nhom","LotSize","QuoteUnit","TickSize_cat","USD_per_quote_unit","IM_per_contract_VND"])
cat["SP_Base"] = cat["SP_Base"].str.upper()

dup = cat["SP_Base"].value_counts()
dup = dup[dup>1]
if not dup.empty:
    st.warning("‚ö†Ô∏è Catalog c√≥ SP_Base tr√πng: " + ", ".join(list(dup.index)))

cat["Contract_Multiplier_cat"] = pd.to_numeric(cat["LotSize"], errors="coerce") * pd.to_numeric(cat["USD_per_quote_unit"], errors="coerce")
cat["IM_per_lot_USD"] = pd.to_numeric(cat["IM_per_contract_VND"], errors="coerce") / float(fx_vnd_usd)

pos = pos.merge(cat, left_on="SP_Base_norm", right_on="SP_Base", how="left", suffixes=("","_cat"))
pos["Contract_Multiplier"] = pos["Mult_POS"].where(pos["Mult_POS"].notna(), pos["Contract_Multiplier_cat"])
pos["TickSize"]            = pos["TickSize_POS"].where(pos["TickSize_POS"].notna(), pos["TickSize_cat"])

missing_mask = pos["Contract_Multiplier"].isna() | pos["TickSize"].isna() | pos["SP_Ten"].isna()
missing = (pos.loc[missing_mask, ["SP_Base","SP_RawToken","M√£ Hƒê"]]
             .drop_duplicates()
             .rename(columns={"SP_Base":"G·ª£i √Ω m√£ base"}))
if not missing.empty:
    st.warning("üìù C√°c m√£ c·∫ßn b·ªï sung v√†o catalog:\n\n" + missing.to_markdown(index=False))

# -------------------- GH√âP L·ªäCH FND/LTD + C·∫¢NH B√ÅO H·ªÜ TH·ªêNG --------------------
sched = SCHEDULE_EMBEDDED.copy()
today = pd.Timestamp.today().normalize()

pos = pos.merge(
    sched[["M√£ Hƒê","FND","LTD","T√™n Hƒê (lich)","S·ªü GD"]],
    on="M√£ Hƒê", how="left"
)
pos["Days_to_FND"] = (pos["FND"] - today).dt.days

soon_mask_all = pos["FND"].notna() & (pos["Days_to_FND"]>=0) & (pos["Days_to_FND"] <= int(alert_days))
soon_df_all = (pos.loc[soon_mask_all, ["TKGD_KEY","T√™n TKGD","M√£ Hƒê","SP_Ten","FND","LTD","Days_to_FND"]]
                 .drop_duplicates()
                 .sort_values(["Days_to_FND","TKGD_KEY","M√£ Hƒê"]))

with st.expander(f"üîî C·∫£nh b√°o FND to√†n h·ªá th·ªëng (‚â§ {alert_days} ng√†y)", expanded=not soon_df_all.empty):
    if soon_df_all.empty:
        st.info("Ch∆∞a c√≥ v·ªã th·∫ø n√†o s·∫Øp t·ªõi ng√†y **th√¥ng b√°o ƒë·∫ßu ti√™n (FND)** trong ng∆∞·ª°ng.")
    else:
        st.success(f"C√≥ **{len(soon_df_all)}** d√≤ng v·ªã th·∫ø s·∫Øp FND trong {alert_days} ng√†y.")
        st.dataframe(soon_df_all, use_container_width=True)
        for _, rr in soon_df_all.head(10).iterrows():
            st.toast(f"‚è∞ {rr['M√£ Hƒê']} | {rr['SP_Ten']}: c√≤n {int(rr['Days_to_FND'])} ng√†y t·ªõi FND", icon="üîî")

def _ensure_data_dir():
    out_dir = os.path.join(os.path.dirname(__file__) if '__file__' in globals() else ".", "data")
    os.makedirs(out_dir, exist_ok=True)
    return out_dir

def save_reminders_csv_ics(df: pd.DataFrame, fname_base: str = "expiry_reminders"):
    out_dir = _ensure_data_dir()
    keep = df.copy()
    # n·∫øu kh√¥ng c√≥ c·ªôt TKGD_KEY/T√™n TKGD th√¨ th√™m r·ªóng ƒë·ªÉ tr√°nh l·ªói
    for col in ["TKGD_KEY","T√™n TKGD"]:
        if col not in keep.columns: keep[col] = ""
    for col in ["FND","LTD"]:
        if col in keep.columns: keep[col] = pd.to_datetime(keep[col], errors="coerce")

    cols = [c for c in ["TKGD_KEY","T√™n TKGD","M√£ Hƒê","SP_Ten","FND","LTD","Days_to_FND","Days_to_Expiry"] if c in keep.columns]
    csv_path = os.path.join(out_dir, f"{fname_base}.csv")
    keep[cols].to_csv(csv_path, index=False, encoding="utf-8-sig")

    # T·∫°o ICS all-day events t·∫°i FND (n·∫øu c√≥), fallback LTD n·∫øu c·∫ßn
    ics_lines = ["BEGIN:VCALENDAR","VERSION:2.0","PRODID:-//mxv-app//expiry//VN"]
    for _, r in keep.iterrows():
        when = r["FND"] if ("FND" in keep.columns and pd.notna(r["FND"])) else (r["LTD"] if ("LTD" in keep.columns and pd.notna(r["LTD"])) else None)
        if when is None: 
            continue
        dt = pd.to_datetime(when).date()
        dt_str = dt.strftime("%Y%m%d")
        uid = f"{r.get('M√£ Hƒê','UNKNOWN')}-{uuid.uuid4().hex[:8]}@mxv-app"
        summary = f"FND {r.get('M√£ Hƒê','')}" if ("FND" in keep.columns and pd.notna(r.get("FND", pd.NaT))) else f"EXP {r.get('M√£ Hƒê','')}"
        desc = f"T√™n KH: {r.get('T√™n TKGD','')} | TKGD: {r.get('TKGD_KEY','')} | LTD: {r.get('LTD','')}"
        ics_lines += [
            "BEGIN:VEVENT",
            f"UID:{uid}",
            f"DTSTAMP:{pd.Timestamp.utcnow().strftime('%Y%m%dT%H%M%SZ')}",
            f"DTSTART;VALUE=DATE:{dt_str}",
            f"SUMMARY:{summary}",
            f"DESCRIPTION:{desc}",
            "END:VEVENT"
        ]
    ics_lines.append("END:VCALENDAR")
    ics_path = os.path.join(out_dir, f"{fname_base}.ics")
    with open(ics_path, "w", encoding="utf-8") as f:
        f.write("\n".join(ics_lines))
    return csv_path, ics_path

if st.button("üíæ L∆∞u nh·∫Øc l·ªãch FND (CSV + ICS) ‚Äî to√†n h·ªá th·ªëng"):
    if soon_df_all.empty:
        st.warning("Kh√¥ng c√≥ d√≤ng s·∫Øp FND theo ng∆∞·ª°ng ƒë·ªÉ l∆∞u.")
    else:
        csv_path, ics_path = save_reminders_csv_ics(soon_df_all, "expiry_reminders")
        st.success(f"ƒê√£ l∆∞u: `{csv_path}` v√† `{ics_path}`")

# -------------------- IM V·ªä TH·∫æ & MGM --------------------
pos["IM_row_file_USD"] = pos["IM_row_file"]
pos["IM_row_calc_USD"] = (pos["IM_per_lot_USD"] * pos["NetQty"].abs()).where(pos["IM_per_lot_USD"].notna())
pos["IM_row_USD"]      = pos["IM_row_file_USD"].where(pos["IM_row_file_USD"].notna(), pos["IM_row_calc_USD"])

m_tkgd  = _find_col(mgm_raw, ["m√£ tkgd","ma tkgd","tkgd"], required=True)
m_ten   = _find_col(mgm_raw, ["t√™n tkgd","ten tkgd"], required=False)
m_equ   = _find_col(mgm_raw, ["gia tri rong ky quy usd","gi√° tr·ªã r√≤ng k√Ω qu·ªπ usd","gi√° tr·ªã r√≤ng k√Ω qu·ªπ (usd)","equity usd","equity_now"], required=True)
m_ratio = _find_col(mgm_raw, ["ty le ky quy hien tai","t·ª∑ l·ªá k√Ω qu·ªπ hi·ªán t·∫°i","margin_now","margin ratio","ty le ky quy hien tai (%)","t·ª∑ l·ªá k√Ω qu·ªπ hi·ªán t·∫°i (%)"], required=True)
m_imtot = _find_col(mgm_raw, ["im_total_required","im tong","im yeu cau","tong ky quy ban dau","ky quy ban dau yeu cau usd"], required=False)

mgm = mgm_raw.copy()
mgm["TKGD_KEY"]     = mgm[m_tkgd].astype(str)
mgm["T√™n TKGD"]     = mgm[m_ten].astype(str) if m_ten else ""
mgm["Equity_now"]   = _num_col(mgm, m_equ)
mgm["Margin_now_%"] = _num_col(mgm, m_ratio)
mgm["IM_total_mgm"] = _num_col(mgm, m_imtot)

im_from_rows = (pos.groupby("TKGD_KEY", dropna=False)["IM_row_USD"]
                  .sum(min_count=1).rename("IM_total_from_rows").reset_index())

acct = (mgm[["TKGD_KEY","T√™n TKGD","Equity_now","Margin_now_%","IM_total_mgm"]]
        .merge(im_from_rows, on="TKGD_KEY", how="left"))

def _pick_im_total(row):
    if pd.notna(row["IM_total_mgm"]) and row["IM_total_mgm"]>0: return row["IM_total_mgm"]
    if pd.notna(row["IM_total_from_rows"]) and row["IM_total_from_rows"]>0: return row["IM_total_from_rows"]
    if pd.notna(row["Margin_now_%"]) and row["Margin_now_%"]>0 and pd.notna(row["Equity_now"]):
        return row["Equity_now"]/(row["Margin_now_%"]/100.0)
    return np.nan

acct["IM_total_required"] = acct.apply(_pick_im_total, axis=1)

# -------------------- ƒê·ªò NH·∫†Y & % MOVE C·∫¶N THI·∫æT --------------------
base = pos[["TKGD_KEY","NetQty","Contract_Multiplier","Gi√° TT"]].copy()
base["NetQty"]              = _safe_num(base["NetQty"])
base["Contract_Multiplier"] = _safe_num(base["Contract_Multiplier"])
base["Gi√° TT"]              = _safe_num(base["Gi√° TT"])

base["dPnL_up_1pct"]   = base["NetQty"] * base["Contract_Multiplier"] * (base["Gi√° TT"] * 0.01)
base["dPnL_down_1pct"] = -base["dPnL_up_1pct"]
base["adverse_up"]     = np.where(base["dPnL_up_1pct"]   < 0, base["dPnL_up_1pct"],   0.0)
base["adverse_down"]   = np.where(base["dPnL_down_1pct"] < 0, base["dPnL_down_1pct"], 0.0)

acc_delta = (base.groupby("TKGD_KEY", dropna=False)
                 .agg(k_up=("adverse_up","sum"),
                      k_down=("adverse_down","sum"))
                 .reset_index())
acct = acct.merge(acc_delta, on="TKGD_KEY", how="left").fillna({"k_up":0.0,"k_down":0.0})

def _need_pct_points(eq, im, k_up, k_dn, target_pct):
    if not (pd.notna(im) and im>0 and pd.notna(eq)): 
        return (np.nan, "down")
    target = im * (target_pct/100.0)
    over = eq - target
    if over <= 0:
        return (0.0, "down")
    loss_up  = abs(min(0.0, k_up))
    loss_dn  = abs(min(0.0, k_dn))
    need_up = np.inf if loss_up==0 else over / loss_up
    need_dn = np.inf if loss_dn==0 else over / loss_dn
    if need_up <= need_dn:
        return (float(max(0.0, need_up)), "up")
    else:
        return (float(max(0.0, need_dn)), "down")

rows = []
for _, r in acct.iterrows():
    eq, im, kup, kdn = r["Equity_now"], r["IM_total_required"], r["k_up"], r["k_down"]
    need, dire = {}, {}
    for t in MARGIN_TARGETS:
        npt, d = _need_pct_points(eq, im, kup, kdn, t)
        need[f"need_to_{t}%_pt"] = npt
        dire[f"dir_{t}%"]        = d
    rows.append({"TKGD_KEY": r["TKGD_KEY"], **need, **dire})
acct = acct.merge(pd.DataFrame(rows), on="TKGD_KEY", how="left")

# -------------------- TH·ªêNG K√ä NH√ìM (GLOBAL) --------------------
def build_product_group_stats(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return pd.DataFrame()
    x = df.copy()
    x["Notional"]      = _safe_num(x["NetQty"]) * _safe_num(x["Contract_Multiplier"]) * _safe_num(x["Gi√° TT"])
    x["GrossNotional"] = x["Notional"].abs()
    x["GrossQty"]      = _safe_num(x["NetQty"]).abs()
    agg = (x.groupby(["SP_Nhom","SP_Base_norm","SP_Ten"], dropna=False)
             .agg(n_contracts=("M√£ Hƒê","nunique"),
                  NetQty=("NetQty","sum"),
                  GrossQty=("GrossQty","sum"),
                  GrossNotional=("GrossNotional","sum"))
             .reset_index())
    total = agg["GrossNotional"].sum()
    agg["Share_%"] = np.where(total>0, agg["GrossNotional"]/total*100.0, 0.0)
    return agg.sort_values(["SP_Nhom","GrossNotional"], ascending=[True, False])

with st.expander("üìä Th·ªëng k√™ nh√≥m ‚Äî To√†n b·ªô d·ªØ li·ªáu", expanded=False):
    stats_all = build_product_group_stats(pos)
    if not stats_all.empty:
        st.dataframe(stats_all, use_container_width=True)
        fig = px.pie(stats_all, names="SP_Base_norm", values="GrossNotional", hole=0.55,
                     title="Th·ªã ph·∫ßn theo Gross Notional (to√†n b·ªô)")
        fig.update_layout(height=420, margin=dict(l=10,r=10,t=60,b=10))
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu sau khi map catalog.")

# -------------------- TRA C·ª®U T√ÄI KHO·∫¢N --------------------
def kpi_row(acc_row: pd.Series, n_positions: int):
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Equity (USD)", f"{float(acc_row['Equity_now']):,.2f}")
    c2.metric("IM t·ªïng (USD)", f"{float(acc_row['IM_total_required']):,.2f}")
    c3.metric("Margin hi·ªán t·∫°i", f"{float(acc_row['Margin_now_%']):.2f}%")
    c4.metric("S·ªë v·ªã th·∫ø", f"{n_positions}")

q = st.text_input("Nh·∫≠p **T√™n KH** ho·∫∑c **M√£ TKGD** (c√≥ th·ªÉ 4‚Äì7 s·ªë cu·ªëi, vd `0006886-A`)").strip()
if not q: st.stop()

acct_idx = (acct[["TKGD_KEY","T√™n TKGD","Equity_now","Margin_now_%","IM_total_required"]]
            .drop_duplicates())

if _looks_like_account(q):
    hits = _resolve_account(q, acct_idx, "TKGD_KEY")
    if hits.empty:
        st.warning(f"Kh√¥ng th·∫•y t√†i kho·∫£n: {q}")
        st.stop()
    if len(hits) > 1:
        st.info("C√≥ nhi·ªÅu t√†i kho·∫£n tr√πng ƒëu√¥i. Ch·ªçn m·ªôt:")
        st.dataframe(hits, use_container_width=True)
        st.stop()

    acc_row = hits.iloc[0]
    key = str(acc_row["TKGD_KEY"])

    sub = pos[pos["TKGD_KEY"].astype(str).str.upper()==key.upper()].copy()
    if sub.empty:
        st.info("T√†i kho·∫£n kh√¥ng c√≥ v·ªã th·∫ø (sau khi map catalog/alias).")
        st.stop()

    # ====== GI√Å C·∫¶N CH·∫†M ======
    for t in MARGIN_TARGETS:
        col_need = f"need_to_{t}%_pt"
        need_pt = acct.loc[acct["TKGD_KEY"]==key, col_need].values[0] if col_need in acct.columns else np.nan
        d       = acct.loc[acct["TKGD_KEY"]==key, f"dir_{t}%"].values[0] if f"dir_{t}%" in acct.columns else "down"

        if not pd.notna(need_pt):
            sub[f"Price_to_{t}"]=np.nan; sub[f"Delta_to_{t}_abs"]=np.nan; sub[f"Delta_to_{t}_%"]=np.nan
            sub[f"Reachable_{t}"]=False; sub[f"Note_{t}"]="Thi·∫øu IM/Equity ho·∫∑c k_up/k_down."
            continue

        need_frac = float(need_pt) / 100.0
        raw_price = sub["Gi√° TT"]*(1+need_frac) if d=="up" else sub["Gi√° TT"]*(1-need_frac)

        tick = sub["TickSize"].fillna(0.0)
        price = pd.Series([(round(p/t)*t if (t and t>0) else p) for p,t in zip(raw_price, tick)], index=sub.index)

        unreachable = (d=="down") & (price<0)
        price_display = price.where(~unreachable, 0.0)

        sub[f"Price_to_{t}"]      = price_display
        sub[f"Delta_to_{t}_abs"]  = price_display - sub["Gi√° TT"]
        sub[f"Delta_to_{t}_%"]    = (price_display/sub["Gi√° TT"] - 1.0) * 100.0
        sub[f"Reachable_{t}"]     = ~unreachable
        sub[f"Note_{t}"]          = np.where(unreachable, "Kh√¥ng th·ªÉ ch·∫°m m·ªëc tr∆∞·ªõc khi gi√° v·ªÅ 0.", "")

    # ====== B·∫¢NG THEO V·ªä TH·∫æ (k√®m l·ªãch) ======
    cols_pos = ["SP_Nhom","SP_Ten","SP_Base_norm","SP_RawToken","T√™n Hƒê","M√£ Hƒê",
                "KL Mua","KL B√°n","NetQty","Gi√° TB","Gi√° TT",
                "Contract_Multiplier","TickSize","IM_per_lot_USD","IM_row_USD",
                "FND","LTD","Days_to_FND"]
    positions_df = sub[[c for c in cols_pos if c in sub.columns]].copy()

    # ====== FND theo T√ÄI KHO·∫¢N ======
    soon_mask_acc = positions_df["FND"].notna() & (positions_df["Days_to_FND"]>=0) & (positions_df["Days_to_FND"] <= int(alert_days))
    soon_acc = positions_df.loc[soon_mask_acc, ["M√£ Hƒê","SP_Ten","FND","LTD","Days_to_FND"]].drop_duplicates().sort_values(["Days_to_FND","M√£ Hƒê"])

    # ====== B·∫¢NG GI√Å C·∫¶N CH·∫†M ======
    view_cols = cols_pos + \
        [f"Price_to_{t}" for t in MARGIN_TARGETS] + \
        sum([[f"Delta_to_{t}_abs",f"Delta_to_{t}_%"] for t in MARGIN_TARGETS], []) + \
        [f"Reachable_{t}" for t in MARGIN_TARGETS] + [f"Note_{t}" for t in MARGIN_TARGETS]
    price_by_position_df = sub[[c for c in dict.fromkeys(view_cols).keys() if c in sub.columns]].copy()

    # ====== G·ªôp theo h·ª£p ƒë·ªìng ======
    grp = pd.DataFrame()
    if {"M√£ Hƒê","SP_Base_norm"}.issubset(sub.columns):
        agg_map = {"NetQty_contract":("NetQty","sum"),
                   "GiaTT_last":("Gi√° TT","last"),
                   "PnL_mult":("Contract_Multiplier","first"),
                   "IM_per_lot_USD":("IM_per_lot_USD","first"),
                   "FND":("FND","first"), "LTD":("LTD","first")}
        for t in MARGIN_TARGETS:
            agg_map[f"Price_to_{t}"]=(f"Price_to_{t}","last")
            agg_map[f"Reachable_{t}"]=(f"Reachable_{t}","all")
        grp = (sub.groupby(["SP_Nhom","SP_Ten","SP_Base_norm","T√™n Hƒê","M√£ Hƒê"], dropna=False)
                 .agg(**agg_map).reset_index())
        grp["Days_to_FND"] = (pd.to_datetime(grp["FND"]) - today).dt.days

    # ====== T·∫†O exp_df CHO TAB ƒê√ÅO H·∫†N Hƒê M·ªû (FIX NameError) ======
    # H·ª£p ƒë·ªìng ƒëang m·ªü: NetQty != 0
    open_mask = _safe_num(sub["NetQty"]) != 0
    exp_df = sub.loc[open_mask, ["SP_Ten","T√™n Hƒê","M√£ Hƒê","FND","LTD"]].drop_duplicates().copy()
    exp_df["FND"] = pd.to_datetime(exp_df["FND"], errors="coerce")
    exp_df["Expiry"] = pd.to_datetime(exp_df["LTD"], errors="coerce")
    exp_df["Days_to_FND"] = (exp_df["FND"] - today).dt.days
    exp_df["Days_to_Expiry"] = (exp_df["Expiry"] - today).dt.days
    exp_df["FND_Status"] = np.where(exp_df["Days_to_FND"].between(0, int(alert_days), inclusive="both"), "S·∫ÆP T·ªöI",
                                    np.where(exp_df["Days_to_FND"]<0, "ƒê√É QUA", "XA"))
    exp_df["Expiry_Status"] = np.where(exp_df["Days_to_Expiry"].between(0, int(alert_days), inclusive="both"), "S·∫ÆP T·ªöI",
                                       np.where(exp_df["Days_to_Expiry"]<0, "ƒê√É QUA", "XA"))

    n_positions = len(positions_df)
    acc_view = acct.loc[acct["TKGD_KEY"]==key].iloc[0]

    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
        ["üîé T·ªïng quan","üìú V·ªã th·∫ø (c√≥ IM)","üéØ Gi√° ph·∫£i ch·∫°m","üì¶ Nh√≥m SP","üß™ Stress test","üóÇÔ∏è Xu·∫•t file","üìÖ ƒê√°o h·∫°n Hƒê m·ªü"]
    )

    with tab1:
        st.subheader("T·ªïng quan t√†i kho·∫£n")
        kpi_row(acc_view, n_positions)

        # H·ªôp c·∫£nh b√°o FND theo t√†i kho·∫£n
        with st.container():
            if soon_acc.empty:
                st.info(f"Kh√¥ng c√≥ h·ª£p ƒë·ªìng s·∫Øp **FND** trong {alert_days} ng√†y.")
            else:
                st.warning(f"‚è∞ H·ª£p ƒë·ªìng s·∫Øp FND trong {alert_days} ng√†y: **{len(soon_acc)}**")
                st.dataframe(soon_acc, use_container_width=True)

                # L∆∞u nh·∫Øc l·ªãch ri√™ng cho t√†i kho·∫£n (CSV + ICS)
                if st.button("üíæ L∆∞u nh·∫Øc l·ªãch FND (CSV + ICS) ‚Äî t√†i kho·∫£n ƒëang xem"):
                    df_to_save = soon_acc.assign(TKGD_KEY=key, **{"T√™n TKGD": acc_row["T√™n TKGD"]})
                    csv_path, ics_path = save_reminders_csv_ics(df_to_save, f"expiry_reminders_{key.replace('/','_')}")
                    st.success(f"ƒê√£ l∆∞u: `{csv_path}` v√† `{ics_path}`")

        try:
            fig = go.Figure(go.Indicator(
                mode="gauge+number", value=float(acc_view["Margin_now_%"]),
                gauge={"axis":{"range":[None, 300]},
                       "threshold":{"line":{"color":"red","width":4},"thickness":0.75,"value":60}},
                title={"text":"Margin % (m·ªëc c·∫£nh b√°o 60%)"}))
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.info(f"Margin hi·ªán t·∫°i: **{float(acc_view['Margin_now_%']):.2f}%**")
        st.dataframe(pd.DataFrame([acc_view])[["TKGD_KEY","T√™n TKGD","Equity_now","IM_total_required","Margin_now_%"]],
                     use_container_width=True)

    with tab2:
        st.markdown("#### V·ªã th·∫ø hi·ªán t·∫°i (GI·ªÆ r√µ **SP_Nhom** + **IM_per_lot_USD**/**IM_row_USD**)")
        st.dataframe(style_positions(positions_df), use_container_width=True)

    with tab3:
        st.markdown("#### Gi√° c·∫ßn ƒë·∫°t theo **t·ª´ng v·ªã th·∫ø** (60/50/40%)")
        st.dataframe(style_positions(price_by_position_df.copy()), use_container_width=True)
        st.markdown("#### Gi√° c·∫ßn ƒë·∫°t ‚Äî g·ªôp theo h·ª£p ƒë·ªìng")
        if not grp.empty:
            st.dataframe(grp, use_container_width=True)
        else:
            st.info("Thi·∫øu M√£ Hƒê / SP_Base_norm ƒë·ªÉ g·ªôp.")

    with tab4:
        st.markdown("#### Th·ªëng k√™ nh√≥m s·∫£n ph·∫©m ‚Äî t√†i kho·∫£n ƒëang xem")
        stats = build_product_group_stats(sub)
        if stats.empty:
            st.info("Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c nh√≥m s·∫£n ph·∫©m.")
        else:
            st.dataframe(stats, use_container_width=True)
            fig = px.pie(stats, names="SP_Base_norm", values="GrossNotional", hole=0.55,
                         title="Th·ªã ph·∫ßn theo Gross Notional (t√†i kho·∫£n)")
            fig.update_layout(height=420, margin=dict(l=10,r=10,t=60,b=10))
            st.plotly_chart(fig, use_container_width=True)

    with tab5:
        st.markdown("#### Stress test theo % bi·∫øn ƒë·ªông gi√°")
        shock = st.slider("Ch·ªçn m·ª©c shock ƒë·ªìng lo·∫°t (%)", -20.0, 20.0, 0.0, 0.5)
        stressed = positions_df.copy()
        if "Gi√° TT" in stressed.columns:
            stressed["Gi√°_TT_stress"] = stressed["Gi√° TT"] * (1 + shock/100.0)
        st.dataframe(stressed[[c for c in ["SP_Nhom","SP_Ten","T√™n Hƒê","M√£ Hƒê","Gi√° TT","Gi√°_TT_stress"] if c in stressed.columns]].round(4),
                     use_container_width=True)

    with tab6:
        st.caption(f"POS: **{pos_sheet}** @header {pos_header} | MGM: **{mgm_sheet}** @header {mgm_header}")
        st.download_button("‚¨áÔ∏è CSV: per-position (c√≥ IM)",
                           price_by_position_df.round(6).to_csv(index=False).encode("utf-8"),
                           "gia_can_cham_positions.csv","text/csv")
        if not grp.empty:
            st.download_button("‚¨áÔ∏è CSV: per-contract",
                               grp.round(6).to_csv(index=False).encode("utf-8"),
                               "gia_can_cham_contracts.csv","text/csv")

    # ---------------- TAB 7: ƒê√ÅO H·∫†N Hƒê M·ªû (ƒê√É FIX exp_df) ----------------
    with tab7:
        st.markdown("### üìÖ ƒê√°o h·∫°n c√°c **h·ª£p ƒë·ªìng ƒëang m·ªü**")
        # KPI nhanh
        nearest_fnd = exp_df["Days_to_FND"].dropna().min() if "Days_to_FND" in exp_df.columns else np.nan
        nearest_exp = exp_df["Days_to_Expiry"].dropna().min() if "Days_to_Expiry" in exp_df.columns else np.nan
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Hƒê ƒëang m·ªü", f"{len(exp_df):,}")
        c2.metric("S·∫Øp FND (‚â§ ng∆∞·ª°ng)", f"{int((exp_df['FND_Status']=='S·∫ÆP T·ªöI').sum())}")
        c3.metric("S·∫Øp ƒë√°o h·∫°n (‚â§ ng∆∞·ª°ng)", f"{int((exp_df['Expiry_Status']=='S·∫ÆP T·ªöI').sum())}")
        val_min = np.nanmin([nearest_fnd, nearest_exp]) if not (pd.isna(nearest_fnd) and pd.isna(nearest_exp)) else np.nan
        c4.metric("G·∫ßn nh·∫•t (ng√†y)", f"{int(val_min) if pd.notna(val_min) else '‚Äî'}")

        st.markdown(f"#### üîî S·∫Øp **FND** trong ‚â§ {alert_days} ng√†y")
        soon_fnd = exp_df.loc[exp_df["FND_Status"]=="S·∫ÆP T·ªöI"].sort_values(["Days_to_FND","M√£ Hƒê"])
        if soon_fnd.empty:
            st.info("Kh√¥ng c√≥ h·ª£p ƒë·ªìng n√†o s·∫Øp FND trong ng∆∞·ª°ng.")
        else:
            st.dataframe(soon_fnd, use_container_width=True)

        st.markdown(f"#### ‚è≥ S·∫Øp **ƒê√ÅO H·∫†N** trong ‚â§ {alert_days} ng√†y")
        soon_exp = exp_df.loc[exp_df["Expiry_Status"]=="S·∫ÆP T·ªöI"].sort_values(["Days_to_Expiry","M√£ Hƒê"])
        if soon_exp.empty:
            st.info("Kh√¥ng c√≥ h·ª£p ƒë·ªìng n√†o s·∫Øp ƒê√ÅO H·∫†N trong ng∆∞·ª°ng.")
        else:
            st.dataframe(soon_exp, use_container_width=True)

        st.markdown("#### Danh s√°ch ƒë·∫ßy ƒë·ªß (Hƒê ƒëang m·ªü)")
        st.dataframe(exp_df.sort_values(["Expiry","FND","M√£ Hƒê"]), use_container_width=True)

        # Xu·∫•t CSV ri√™ng cho tab n√†y
        st.download_button(
            "‚¨áÔ∏è CSV: ƒê√°o h·∫°n Hƒê ƒëang m·ªü (t√†i kho·∫£n)",
            exp_df.to_csv(index=False).encode("utf-8"),
            file_name=f"expiry_open_positions_{key.replace('/','_')}.csv",
            mime="text/csv"
        )

        # L∆∞u nh·∫Øc l·ªãch cho t·∫•t c·∫£ Hƒê m·ªü (FND/Expiry)
        if st.button("üíæ L∆∞u nh·∫Øc l·ªãch FND/Expiry (CSV + ICS) ‚Äî t·∫•t c·∫£ Hƒê ƒëang m·ªü"):
            try:
                data_to_save = exp_df.assign(TKGD_KEY=key, **{"T√™n TKGD": acc_row["T√™n TKGD"]})
                csv_path, ics_path = save_reminders_csv_ics(
                    data_to_save, f"expiry_all_open_{key.replace('/','_')}"
                )
                st.success(f"ƒê√£ l∆∞u: `{csv_path}` v√† `{ics_path}`")
            except Exception as e:
                st.error(f"Kh√¥ng l∆∞u ƒë∆∞·ª£c file nh·∫Øc l·ªãch: {e}")

else:
    # T√¨m theo T√™n KH
    kh_key = _strip_accents(q)
    idx = acct_idx.copy()
    idx["KH_KEY"] = idx["T√™n TKGD"].map(_strip_accents)
    hits = idx[idx["KH_KEY"].str.contains(kh_key, na=False)]
    if hits.empty:
        st.warning(f"Kh√¥ng th·∫•y KH: {q}")
        st.stop()
    st.info("C√°c t√†i kho·∫£n thu·ªôc KH:")
    st.dataframe(hits[["TKGD_KEY","T√™n TKGD"]], use_container_width=True)
    st.caption("‚Üí Nh·∫≠p ch√≠nh x√°c **M√£ TKGD** ·ªü √¥ tr√™n ƒë·ªÉ xem chi ti·∫øt.")
